{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salvatoremariocarota/opt/anaconda3/envs/multi/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/salvatoremariocarota/opt/anaconda3/envs/multi/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "from SwinIR.models.network_swinir import SwinIR as net\n",
    "#from SwinIR.utils import util_calculate_psnr_ssim as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_lq, model, tile ,window_size):\n",
    "\n",
    "    tile_overlap = 32\n",
    "\n",
    "    if tile is None:\n",
    "        # test the image as a whole\n",
    "        output = model(img_lq)\n",
    "    else:\n",
    "        # test the image tile by tile\n",
    "        b, c, h, w = img_lq.size()\n",
    "        tile = min(tile, h, w)\n",
    "        assert tile % window_size == 0, \"tile size should be a multiple of window_size\"\n",
    "        tile_overlap = tile_overlap\n",
    "        sf = 8\n",
    "\n",
    "        stride = tile - tile_overlap\n",
    "        h_idx_list = list(range(0, h-tile, stride)) + [h-tile]\n",
    "        w_idx_list = list(range(0, w-tile, stride)) + [w-tile]\n",
    "        E = torch.zeros(b, c, h*sf, w*sf).type_as(img_lq)\n",
    "        W = torch.zeros_like(E)\n",
    "\n",
    "        for h_idx in h_idx_list:\n",
    "            for w_idx in w_idx_list:\n",
    "                in_patch = img_lq[..., h_idx:h_idx+tile, w_idx:w_idx+tile]\n",
    "                out_patch = model(in_patch)\n",
    "                out_patch_mask = torch.ones_like(out_patch)\n",
    "\n",
    "                E[..., h_idx*sf:(h_idx+tile)*sf, w_idx*sf:(w_idx+tile)*sf].add_(out_patch)\n",
    "                W[..., h_idx*sf:(h_idx+tile)*sf, w_idx*sf:(w_idx+tile)*sf].add_(out_patch_mask)\n",
    "        output = E.div_(W)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hight_res(): \n",
    "\n",
    "    model_path = \"model_zoo/swinir/001_classicalSR_DIV2K_s48w8_SwinIR-M_x8.pth\"\n",
    "    scale = 8\n",
    "    training_patch_size = 48\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f'loading model from {model_path}')\n",
    "    else:\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        url = 'https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/{}'.format(os.path.basename(model_path))\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        print(f'downloading model {model_path}')\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "\n",
    "    #----- define_model ---- -\n",
    "\n",
    "    model = net(upscale=scale, in_chans=3, img_size=training_patch_size, window_size=8,\n",
    "                    img_range=1., depths=[6, 6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6],\n",
    "                    mlp_ratio=2, upsampler='pixelshuffle', resi_connection='1conv')\n",
    "    param_key_g = 'params'\n",
    "\n",
    "    pretrained_model = torch.load(model_path)\n",
    "    model.load_state_dict(pretrained_model[param_key_g] if param_key_g in pretrained_model.keys() else pretrained_model, strict=True)\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    #----- set_up ------ \n",
    "\n",
    "    save_dir = f'results/swinir_x{scale}'\n",
    "    folder = './frames/'\n",
    "    border = scale\n",
    "    window_size = 8\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for idx, path in enumerate(sorted(glob.glob(os.path.join(folder, '*')))):\n",
    "        # read image\n",
    "        imgname = \"frame.png\"\n",
    "\n",
    "        img_lq = cv2.imread(f'{folder}/{imgname}', cv2.IMREAD_COLOR).astype(np.float32) / 255.\n",
    "\n",
    "\n",
    "        img_lq = np.transpose(img_lq if img_lq.shape[2] == 1 else img_lq[:, :, [2, 1, 0]], (2, 0, 1))  # HCW-BGR to CHW-RGB\n",
    "        img_lq = torch.from_numpy(img_lq).float().unsqueeze(0).to(device)  # CHW-RGB to NCHW-RGB\n",
    "\n",
    "        # inference\n",
    "        with torch.no_grad():\n",
    "            # pad input image to be a multiple of window_size\n",
    "            _, _, h_old, w_old = img_lq.size()\n",
    "            h_pad = (h_old // window_size + 1) * window_size - h_old\n",
    "            w_pad = (w_old // window_size + 1) * window_size - w_old\n",
    "            img_lq = torch.cat([img_lq, torch.flip(img_lq, [2])], 2)[:, :, :h_old + h_pad, :]\n",
    "            img_lq = torch.cat([img_lq, torch.flip(img_lq, [3])], 3)[:, :, :, :w_old + w_pad]\n",
    "            output = test(img_lq, model, None ,window_size)\n",
    "            output = output[..., :h_old * scale, :w_old * scale]\n",
    "\n",
    "        # save image\n",
    "        output = output.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "        if output.ndim == 3:\n",
    "            output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))  # CHW-RGB to HCW-BGR\n",
    "        output = (output * 255.0).round().astype(np.uint8)  # float32 to uint8\n",
    "        cv2.imwrite(f'{save_dir}/{imgname}_SwinIR.png', output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salvatoremariocarota/opt/anaconda3/envs/multi/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from model_zoo/swinir/001_classicalSR_DIV2K_s48w8_SwinIR-M_x8.pth\n"
     ]
    }
   ],
   "source": [
    "hight_res()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
